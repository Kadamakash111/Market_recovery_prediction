# Market_recovery_prediction
Market recovery prediction using classification model
Introduction:
Machine learning being a vast area for data analysis and prediction analysis I have opted for different algorithms for regression and classification for my analysis. Different technique and methods are used for prediction and analysis of data based on the dataset chosen from data.gov. The dataset used for Classification was of micro market recovery accessed from the URL; https://catalog.data.gov/dataset/micro-market-recovery-program-violations-and-inspections-89dbf. And Dataset highway toll for regression model was taken from the URL: https://catalog.data.gov/dataset/highway-travel-permit-single-use .
Classification Model
Classification is the process of predicting the class of given data points. Classification problem is mostly when the output variable is a category such as “Apple”,” Banana”,” Mango” or “Red”, “Black”. which can be identified as a particular category. Classification either predicts the label or classify the data based on the training dataset. Number of classification model includes Decision tree, random forest, gradient-boosted tree, multilayer perceptron, one-vs-rest, and Naive Bayes.
For classification, I have selected a different dataset micro market recovery program for violation and inspection. Here in this I have 43 attributes and 216109 rows. Data provides the information of the type of permits/case released, its description, inspection type and violations for the particular type of permits and inspection status. With the information provided for the inspection and violation rules I have predicated the status for inspection status. As the data for inspection has multiple status like Closed, Open or Failed. After studying the dataset and the details I had opted for decision tree algorithm for predicting the status of the inspection. As Inspection status was treated as the label and other attributes where selected as the feature. Using the co-relation heat map few columns which were not relevant was ignored as it would have negative impact on the accuracy and prediction results. 
Pre-processing of Data
Using different library like pandas and NumPy and packages dataset was imported the dataset into python. Once the dataset was uploaded it required pre-processing and needed to be made in a structured form. As pre-processing was explained in question one most of the new thing and handling of data was learned using the same knowledge pre-processing was performed on the dataset. As there where total 43 attributes in which most of them where not useful so I decided to drop the few columns. And new data frame was created with required columns and proper naming conventions was given. As there were 216109 rows in the dataset there were few missing values in the columns which was must to replace. After checking the dataset using market_recovery.isnull().sum() all the details of the missing values columns were glanced. Few columns like Central_Business_District where having more than 213522 values which was difficult to replace as it would have an impact on the results so that column was dropped.  Using the Sklearn pre-processing library simple imputer was used to imputing the missing values with the strategy of Most frequent occurrence Fig 1.1. Since the dataset was huge and missing values very few so I selected this approach which provided a good overall result.
                             

Then the feature and the target columns where selected. Using the features and target column as inspected_status I had split the dataset in ratio of 70:30 using train_test_split. The data was split into X_train, X_test,y_train and y_test . Once the data was split, the decision tree classifier for classifying the data. Since features has to be in float, I had to convert the columns with string into float using the label encoder i.e. using the preprocessing.labelencoder. Since the decision tree works with numerical data and mathematical data converting the string variable was important as it was giving error. Using the Label encoder few of the columns which where string was converted using the fit_transform and then it was applied to the decision tree classifier. 

 
Observation and Results:
Once the conversion for the features where completed then I used the model selection for decision tree and used the fit model with X_train and _X_test then using the predict function got the results for the test dataset. Accuracy varied from 88 percent to 92 percent. After few iterations and replacing few columns finally the accuracy of the model was achieved to 92.32 percent Fig.1.3 the result was much better and gave more appropriate results and predicted the values appropriately.
  
                                   

